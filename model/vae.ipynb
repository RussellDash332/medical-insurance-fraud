{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  \n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath(f):\n",
    "    d = os.path.join(os.path.dirname(os.getcwd()), 'processed_data', f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training and test datasets\n",
    "train_data=pd.read_csv(filepath(\"final_training_set.csv\"))\n",
    "test_data=pd.read_csv(filepath(\"final_test_set.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>ChronicCond_Alzheimer</th>\n",
       "      <th>...</th>\n",
       "      <th>procedure_9</th>\n",
       "      <th>procedure_10</th>\n",
       "      <th>procedure_11</th>\n",
       "      <th>procedure_12</th>\n",
       "      <th>procedure_13</th>\n",
       "      <th>procedure_14</th>\n",
       "      <th>procedure_15</th>\n",
       "      <th>procedure_16</th>\n",
       "      <th>procedure_17</th>\n",
       "      <th>procedure_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM733300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM372475</td>\n",
       "      <td>700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM748221</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM272936</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM58316</td>\n",
       "      <td>36000</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558206</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM582682</td>\n",
       "      <td>1100</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558207</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM553988</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558208</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM610854</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558209</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM691834</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558210</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM701529</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558211 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Provider  PotentialFraud    ClaimID  InscClaimAmtReimbursed  \\\n",
       "0       PRV51001               0  CLM733300                      20   \n",
       "1       PRV51001               0  CLM372475                     700   \n",
       "2       PRV51001               0  CLM748221                     900   \n",
       "3       PRV51001               0  CLM272936                     500   \n",
       "4       PRV51001               0   CLM58316                   36000   \n",
       "...          ...             ...        ...                     ...   \n",
       "558206  PRV57763               0  CLM582682                    1100   \n",
       "558207  PRV57763               0  CLM553988                     200   \n",
       "558208  PRV57763               0  CLM610854                      80   \n",
       "558209  PRV57763               0  CLM691834                    3300   \n",
       "558210  PRV57763               0  CLM701529                      40   \n",
       "\n",
       "        DeductibleAmtPaid  inpatient  Gender  Race  RenalDiseaseIndicator  \\\n",
       "0                     0.0          0       1     1                      1   \n",
       "1                     0.0          0       1     1                      0   \n",
       "2                     0.0          0       2     1                      0   \n",
       "3                     0.0          0       1     1                      0   \n",
       "4                  1068.0          1       1     1                      0   \n",
       "...                   ...        ...     ...   ...                    ...   \n",
       "558206               40.0          0       2     2                      0   \n",
       "558207                0.0          0       1     2                      0   \n",
       "558208                0.0          0       2     1                      1   \n",
       "558209                0.0          0       2     2                      0   \n",
       "558210                0.0          0       2     2                      0   \n",
       "\n",
       "        ChronicCond_Alzheimer  ...  procedure_9  procedure_10  procedure_11  \\\n",
       "0                           1  ...            0             0             0   \n",
       "1                           1  ...            0             0             0   \n",
       "2                           0  ...            0             0             0   \n",
       "3                           1  ...            0             0             0   \n",
       "4                           0  ...            0             0             0   \n",
       "...                       ...  ...          ...           ...           ...   \n",
       "558206                      1  ...            0             0             0   \n",
       "558207                      0  ...            0             0             0   \n",
       "558208                      0  ...            0             0             0   \n",
       "558209                      0  ...            0             0             0   \n",
       "558210                      0  ...            0             0             0   \n",
       "\n",
       "        procedure_12  procedure_13  procedure_14  procedure_15  procedure_16  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "558206             0             0             0             0             0   \n",
       "558207             0             0             0             0             0   \n",
       "558208             0             0             0             0             0   \n",
       "558209             0             0             0             0             0   \n",
       "558210             0             0             0             0             0   \n",
       "\n",
       "        procedure_17  procedure_18  \n",
       "0                  0             0  \n",
       "1                  0             0  \n",
       "2                  0             0  \n",
       "3                  0             0  \n",
       "4                  0             0  \n",
       "...              ...           ...  \n",
       "558206             0             0  \n",
       "558207             0             0  \n",
       "558208             0             0  \n",
       "558209             0             0  \n",
       "558210             0             0  \n",
       "\n",
       "[558211 rows x 65 columns]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = train_data[\"ClaimID\"]\n",
    "train_data = train_data.drop(\n",
    "    [\"ClaimID\"],\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider\n",
      "PotentialFraud\n",
      "InscClaimAmtReimbursed\n",
      "DeductibleAmtPaid\n",
      "inpatient\n",
      "Gender\n",
      "Race\n",
      "RenalDiseaseIndicator\n",
      "ChronicCond_Alzheimer\n",
      "ChronicCond_Heartfailure\n",
      "ChronicCond_KidneyDisease\n",
      "ChronicCond_Cancer\n",
      "ChronicCond_ObstrPulmonary\n",
      "ChronicCond_Depression\n",
      "ChronicCond_Diabetes\n",
      "ChronicCond_IschemicHeart\n",
      "ChronicCond_Osteoporasis\n",
      "ChronicCond_rheumatoidarthritis\n",
      "ChronicCond_stroke\n",
      "IPAnnualReimbursementAmt\n",
      "IPAnnualDeductibleAmt\n",
      "OPAnnualReimbursementAmt\n",
      "OPAnnualDeductibleAmt\n",
      "age\n",
      "claim_duration\n",
      "time_under_care\n",
      "admitDiagInFinalDiagnosis\n",
      "diagnosis_1\n",
      "diagnosis_2\n",
      "diagnosis_3\n",
      "diagnosis_4\n",
      "diagnosis_5\n",
      "diagnosis_6\n",
      "diagnosis_7\n",
      "diagnosis_8\n",
      "diagnosis_9\n",
      "diagnosis_10\n",
      "diagnosis_11\n",
      "diagnosis_12\n",
      "diagnosis_13\n",
      "diagnosis_14\n",
      "diagnosis_15\n",
      "diagnosis_16\n",
      "diagnosis_17\n",
      "diagnosis_18\n",
      "diagnosis_19\n",
      "procedure_1\n",
      "procedure_2\n",
      "procedure_3\n",
      "procedure_4\n",
      "procedure_5\n",
      "procedure_6\n",
      "procedure_7\n",
      "procedure_8\n",
      "procedure_9\n",
      "procedure_10\n",
      "procedure_11\n",
      "procedure_12\n",
      "procedure_13\n",
      "procedure_14\n",
      "procedure_15\n",
      "procedure_16\n",
      "procedure_17\n",
      "procedure_18\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_encode(df, col):\n",
    "    \"\"\"\n",
    "    Return dataset including the minmax encoded column and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be numeric\n",
    "    \"\"\"\n",
    "\n",
    "    maxx = df[col].max()\n",
    "    minx = df[col].min()\n",
    "    out = list(map(lambda x: (x-minx)/(maxx-minx), df[col]))\n",
    "    new_colname = col + \"_minmax\"\n",
    "    df[new_colname] = out\n",
    "    return df.drop(\n",
    "        [col],\n",
    "        axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col):\n",
    "    \"\"\"\n",
    "    Returns the dataset including the one hot encoded columns and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be a Series that represents a categorical variable\n",
    "    \"\"\"\n",
    "    ohe_cols = pd.get_dummies(df[col], prefix = col)\n",
    "    output = pd.concat(\n",
    "        [df, ohe_cols],\n",
    "        axis = 1,\n",
    "    ).drop(\n",
    "        [col],\n",
    "        axis = 1\n",
    "    )\n",
    "    return output\n",
    "\n",
    "def frequency_encode(df, col):\n",
    "    \"\"\"\n",
    "    Returns the dataset including the frequency encoded column and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be a Series that represents a categorical variable with high cardinality\n",
    "    \"\"\"\n",
    "    val_counts = df[col].value_counts().to_dict()\n",
    "    total = len(col)\n",
    "    out = []\n",
    "    for x in df[col]:\n",
    "        out.append(val_counts[x]/total)\n",
    "    new_colname = col + '_freq'\n",
    "    df[new_colname] = out\n",
    "    df.drop(\n",
    "        [col],\n",
    "        axis = 1,\n",
    "        inplace = True\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procedure_1 has been removed as it is constant\n",
      "procedure_2 has been removed as it is constant\n",
      "procedure_3 has been removed as it is constant\n"
     ]
    }
   ],
   "source": [
    "freq_encoded_cols = []\n",
    "ohe_cols = []\n",
    "num_cols = []\n",
    "unique_threshold = 30\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].nunique() == 1:\n",
    "        print(col,\"has been removed as it is constant\")\n",
    "        train_data.drop([col], axis=1, inplace=True)\n",
    "    elif train_data[col].nunique() == 2: # Binary columns\n",
    "        continue\n",
    "    elif train_data[col].dtype in ['int64','float64']:\n",
    "        train_data[col] = train_data[col].fillna(train_data[col].median())\n",
    "        num_cols.append(col)\n",
    "    elif train_data[col].nunique() > unique_threshold:\n",
    "        freq_encoded_cols.append(col)\n",
    "    elif 2 < train_data[col].nunique() <= unique_threshold:\n",
    "        ohe_cols.append(col)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    if col in num_cols:\n",
    "        train_data = minmax_encode(train_data, col)\n",
    "    elif col in ohe_cols:\n",
    "        train_data = one_hot_encode(train_data, col)\n",
    "    elif col in freq_encoded_cols:\n",
    "        try:\n",
    "            train_data = frequency_encode(train_data, col)\n",
    "        except:\n",
    "            print(col)\n",
    "    elif train_data[col].nunique() == 1:\n",
    "        train_data.drop(\n",
    "            [col],\n",
    "            axis = 1,\n",
    "            inplace = True\n",
    "        )\n",
    "    else:\n",
    "        train_data[col] = train_data[col].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"PotentialFraud\"]\n",
    "train_data.drop(\n",
    "    [\"PotentialFraud\"],\n",
    "    axis = 1,\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in as a Pytorch tensor\n",
    "BATCH_SIZE = 64\n",
    "train_tensor = torch.tensor(train_data.values.tolist())\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = train_tensor,\n",
    "    shuffle = True,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_col_count = len(train_data.columns)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "\n",
    "        self.L1 = curr_col_count\n",
    "        self.L2 = curr_col_count//2\n",
    "        self.L3 = curr_col_count//4\n",
    "\n",
    "        self.mean_layer = nn.Linear(self.L3,2)\n",
    "        self.var_layer = nn.Linear(self.L3,2)\n",
    "\n",
    "    def encode(self,x):\n",
    "        model = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L1, self.L2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L2, self.L3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        latent_output = model(x)\n",
    "        mean,var = self.mean_layer(latent_output), self.var_layer(latent_output)\n",
    "        return mean, var\n",
    "    \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(2, self.L3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(self.L3, self.L2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L2, self.L1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        return model(x)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean, var = self.encode(x)\n",
    "        z = self.reparameterization(mean, var)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = VAE().to(device)\n",
    "\n",
    "# Define loss function (sum of binary crossentropy and KL Divergence)\n",
    "def loss_function(x,x_hat,mean,var):\n",
    "    reproduction_loss= nn.functional.binary_cross_entropy(x_hat,x,reduction=\"sum\")\n",
    "    KL_Divergence = -0.5 * torch.sum(1+var-mean.pow(2) - var.exp())\n",
    "    return reproduction_loss+KL_Divergence\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, x in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat, mean, var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, var)\n",
    "            overall_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*BATCH_SIZE))\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 \tAverage Loss:  17897609841.625122\n",
      "\tEpoch 2 \tAverage Loss:  29063455.99513741\n",
      "\tEpoch 3 \tAverage Loss:  9381604315.615726\n",
      "\tEpoch 4 \tAverage Loss:  208.87940243787926\n",
      "\tEpoch 5 \tAverage Loss:  218.05860723783337\n",
      "\tEpoch 6 \tAverage Loss:  2085.2944261859425\n",
      "\tEpoch 7 \tAverage Loss:  195.4147152169818\n",
      "\tEpoch 8 \tAverage Loss:  36.23189568019356\n",
      "\tEpoch 9 \tAverage Loss:  23.649729160705146\n",
      "\tEpoch 10 \tAverage Loss:  1530.8263686804617\n",
      "\tEpoch 11 \tAverage Loss:  71.46109692585958\n",
      "\tEpoch 12 \tAverage Loss:  124.9961467052143\n",
      "\tEpoch 13 \tAverage Loss:  77.33498806022389\n",
      "\tEpoch 14 \tAverage Loss:  70.33267534101017\n",
      "\tEpoch 15 \tAverage Loss:  21.624257386058765\n",
      "\tEpoch 16 \tAverage Loss:  132.28070886815476\n",
      "\tEpoch 17 \tAverage Loss:  43407512.01159772\n",
      "\tEpoch 18 \tAverage Loss:  1171.038876728327\n",
      "\tEpoch 19 \tAverage Loss:  99725613.40346871\n",
      "\tEpoch 20 \tAverage Loss:  19781.15306460737\n",
      "\tEpoch 21 \tAverage Loss:  68.2211427066447\n",
      "\tEpoch 22 \tAverage Loss:  110.51173852899703\n",
      "\tEpoch 23 \tAverage Loss:  364.6267649132081\n",
      "\tEpoch 24 \tAverage Loss:  7208.879379986826\n",
      "\tEpoch 25 \tAverage Loss:  20.52278213937248\n",
      "\tEpoch 26 \tAverage Loss:  10.381702710499159\n",
      "\tEpoch 27 \tAverage Loss:  77706.51153180114\n",
      "\tEpoch 28 \tAverage Loss:  6.579970979056372\n",
      "\tEpoch 29 \tAverage Loss:  3934.4520682735442\n",
      "\tEpoch 30 \tAverage Loss:  11784.866046744635\n",
      "\tEpoch 31 \tAverage Loss:  429.7404037520402\n",
      "\tEpoch 32 \tAverage Loss:  113.19374713564761\n",
      "\tEpoch 33 \tAverage Loss:  247.50604535267183\n",
      "\tEpoch 34 \tAverage Loss:  104.98355327451264\n",
      "\tEpoch 35 \tAverage Loss:  11.573435533049455\n",
      "\tEpoch 36 \tAverage Loss:  23.461367894766173\n",
      "\tEpoch 37 \tAverage Loss:  396171.4109560907\n",
      "\tEpoch 38 \tAverage Loss:  12.135850614758978\n",
      "\tEpoch 39 \tAverage Loss:  74.58440936461854\n",
      "\tEpoch 40 \tAverage Loss:  15.658023593295088\n",
      "\tEpoch 41 \tAverage Loss:  15.9098876907147\n",
      "\tEpoch 42 \tAverage Loss:  93.87711210202744\n",
      "\tEpoch 43 \tAverage Loss:  88.9275269654059\n",
      "\tEpoch 44 \tAverage Loss:  10.87478664921111\n",
      "\tEpoch 45 \tAverage Loss:  71404.75503170189\n",
      "\tEpoch 46 \tAverage Loss:  346.17368504736464\n",
      "\tEpoch 47 \tAverage Loss:  1104.572493874297\n",
      "\tEpoch 48 \tAverage Loss:  -2.4022500253111856\n",
      "\tEpoch 49 \tAverage Loss:  47.13747448517734\n",
      "\tEpoch 50 \tAverage Loss:  10.023893363047728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(178.5784, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "train(model, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
