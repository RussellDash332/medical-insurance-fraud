{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  \n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filepath(f):\n",
    "    d = os.path.join(os.path.dirname(os.getcwd()), 'processed_data', f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training and test datasets\n",
    "train_data=pd.read_csv(filepath(\"final_training_set.csv\"))\n",
    "test_data=pd.read_csv(filepath(\"final_test_set.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Provider</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>inpatient</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>ChronicCond_Alzheimer</th>\n",
       "      <th>...</th>\n",
       "      <th>procedure_9</th>\n",
       "      <th>procedure_10</th>\n",
       "      <th>procedure_11</th>\n",
       "      <th>procedure_12</th>\n",
       "      <th>procedure_13</th>\n",
       "      <th>procedure_14</th>\n",
       "      <th>procedure_15</th>\n",
       "      <th>procedure_16</th>\n",
       "      <th>procedure_17</th>\n",
       "      <th>procedure_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM733300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM372475</td>\n",
       "      <td>700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM748221</td>\n",
       "      <td>900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM272936</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRV51001</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM58316</td>\n",
       "      <td>36000</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558206</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM582682</td>\n",
       "      <td>1100</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558207</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM553988</td>\n",
       "      <td>200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558208</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM610854</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558209</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM691834</td>\n",
       "      <td>3300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558210</th>\n",
       "      <td>PRV57763</td>\n",
       "      <td>0</td>\n",
       "      <td>CLM701529</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558211 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Provider  PotentialFraud    ClaimID  InscClaimAmtReimbursed  \\\n",
       "0       PRV51001               0  CLM733300                      20   \n",
       "1       PRV51001               0  CLM372475                     700   \n",
       "2       PRV51001               0  CLM748221                     900   \n",
       "3       PRV51001               0  CLM272936                     500   \n",
       "4       PRV51001               0   CLM58316                   36000   \n",
       "...          ...             ...        ...                     ...   \n",
       "558206  PRV57763               0  CLM582682                    1100   \n",
       "558207  PRV57763               0  CLM553988                     200   \n",
       "558208  PRV57763               0  CLM610854                      80   \n",
       "558209  PRV57763               0  CLM691834                    3300   \n",
       "558210  PRV57763               0  CLM701529                      40   \n",
       "\n",
       "        DeductibleAmtPaid  inpatient  Gender  Race  RenalDiseaseIndicator  \\\n",
       "0                     0.0          0       1     1                      1   \n",
       "1                     0.0          0       1     1                      0   \n",
       "2                     0.0          0       2     1                      0   \n",
       "3                     0.0          0       1     1                      0   \n",
       "4                  1068.0          1       1     1                      0   \n",
       "...                   ...        ...     ...   ...                    ...   \n",
       "558206               40.0          0       2     2                      0   \n",
       "558207                0.0          0       1     2                      0   \n",
       "558208                0.0          0       2     1                      1   \n",
       "558209                0.0          0       2     2                      0   \n",
       "558210                0.0          0       2     2                      0   \n",
       "\n",
       "        ChronicCond_Alzheimer  ...  procedure_9  procedure_10  procedure_11  \\\n",
       "0                           1  ...            0             0             0   \n",
       "1                           1  ...            0             0             0   \n",
       "2                           0  ...            0             0             0   \n",
       "3                           1  ...            0             0             0   \n",
       "4                           0  ...            0             0             0   \n",
       "...                       ...  ...          ...           ...           ...   \n",
       "558206                      1  ...            0             0             0   \n",
       "558207                      0  ...            0             0             0   \n",
       "558208                      0  ...            0             0             0   \n",
       "558209                      0  ...            0             0             0   \n",
       "558210                      0  ...            0             0             0   \n",
       "\n",
       "        procedure_12  procedure_13  procedure_14  procedure_15  procedure_16  \\\n",
       "0                  0             0             0             0             0   \n",
       "1                  0             0             0             0             0   \n",
       "2                  0             0             0             0             0   \n",
       "3                  0             0             0             0             0   \n",
       "4                  0             0             0             0             0   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "558206             0             0             0             0             0   \n",
       "558207             0             0             0             0             0   \n",
       "558208             0             0             0             0             0   \n",
       "558209             0             0             0             0             0   \n",
       "558210             0             0             0             0             0   \n",
       "\n",
       "        procedure_17  procedure_18  \n",
       "0                  0             0  \n",
       "1                  0             0  \n",
       "2                  0             0  \n",
       "3                  0             0  \n",
       "4                  0             0  \n",
       "...              ...           ...  \n",
       "558206             0             0  \n",
       "558207             0             0  \n",
       "558208             0             0  \n",
       "558209             0             0  \n",
       "558210             0             0  \n",
       "\n",
       "[558211 rows x 65 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = train_data[\"ClaimID\"]\n",
    "train_data = train_data.drop(\n",
    "    [\"ClaimID\"],\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider\n",
      "PotentialFraud\n",
      "InscClaimAmtReimbursed\n",
      "DeductibleAmtPaid\n",
      "inpatient\n",
      "Gender\n",
      "Race\n",
      "RenalDiseaseIndicator\n",
      "ChronicCond_Alzheimer\n",
      "ChronicCond_Heartfailure\n",
      "ChronicCond_KidneyDisease\n",
      "ChronicCond_Cancer\n",
      "ChronicCond_ObstrPulmonary\n",
      "ChronicCond_Depression\n",
      "ChronicCond_Diabetes\n",
      "ChronicCond_IschemicHeart\n",
      "ChronicCond_Osteoporasis\n",
      "ChronicCond_rheumatoidarthritis\n",
      "ChronicCond_stroke\n",
      "IPAnnualReimbursementAmt\n",
      "IPAnnualDeductibleAmt\n",
      "OPAnnualReimbursementAmt\n",
      "OPAnnualDeductibleAmt\n",
      "age\n",
      "claim_duration\n",
      "time_under_care\n",
      "admitDiagInFinalDiagnosis\n",
      "diagnosis_1\n",
      "diagnosis_2\n",
      "diagnosis_3\n",
      "diagnosis_4\n",
      "diagnosis_5\n",
      "diagnosis_6\n",
      "diagnosis_7\n",
      "diagnosis_8\n",
      "diagnosis_9\n",
      "diagnosis_10\n",
      "diagnosis_11\n",
      "diagnosis_12\n",
      "diagnosis_13\n",
      "diagnosis_14\n",
      "diagnosis_15\n",
      "diagnosis_16\n",
      "diagnosis_17\n",
      "diagnosis_18\n",
      "diagnosis_19\n",
      "procedure_1\n",
      "procedure_2\n",
      "procedure_3\n",
      "procedure_4\n",
      "procedure_5\n",
      "procedure_6\n",
      "procedure_7\n",
      "procedure_8\n",
      "procedure_9\n",
      "procedure_10\n",
      "procedure_11\n",
      "procedure_12\n",
      "procedure_13\n",
      "procedure_14\n",
      "procedure_15\n",
      "procedure_16\n",
      "procedure_17\n",
      "procedure_18\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_encode(df, col):\n",
    "    \"\"\"\n",
    "    Return dataset including the minmax encoded column and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be numeric\n",
    "    \"\"\"\n",
    "\n",
    "    maxx = df[col].max()\n",
    "    minx = df[col].min()\n",
    "    out = list(map(lambda x: (x-minx)/(maxx-minx), df[col]))\n",
    "    new_colname = col + \"_minmax\"\n",
    "    df[new_colname] = out\n",
    "    return df.drop(\n",
    "        [col],\n",
    "        axis = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col):\n",
    "    \"\"\"\n",
    "    Returns the dataset including the one hot encoded columns and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be a Series that represents a categorical variable\n",
    "    \"\"\"\n",
    "    ohe_cols = pd.get_dummies(df[col], prefix = col)\n",
    "    output = pd.concat(\n",
    "        [df, ohe_cols],\n",
    "        axis = 1,\n",
    "    ).drop(\n",
    "        [col],\n",
    "        axis = 1\n",
    "    )\n",
    "    return output\n",
    "\n",
    "def frequency_encode(df, col):\n",
    "    \"\"\"\n",
    "    Returns the dataset including the frequency encoded column and excluding the original column\n",
    "\n",
    "    Constraints:\n",
    "    - col must be a String\n",
    "    - df must be a Pandas Dataframe\n",
    "    - df[col] must be a Series that represents a categorical variable with high cardinality\n",
    "    \"\"\"\n",
    "    val_counts = df[col].value_counts().to_dict()\n",
    "    total = len(col)\n",
    "    out = []\n",
    "    for x in df[col]:\n",
    "        out.append(val_counts[x]/total)\n",
    "    new_colname = col + '_freq'\n",
    "    df[new_colname] = out\n",
    "    df.drop(\n",
    "        [col],\n",
    "        axis = 1,\n",
    "        inplace = True\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "procedure_1 has been removed as it is constant\n",
      "procedure_2 has been removed as it is constant\n",
      "procedure_3 has been removed as it is constant\n"
     ]
    }
   ],
   "source": [
    "freq_encoded_cols = []\n",
    "ohe_cols = []\n",
    "num_cols = []\n",
    "unique_threshold = 30\n",
    "\n",
    "for col in train_data.columns:\n",
    "    if train_data[col].nunique() == 1:\n",
    "        print(col,\"has been removed as it is constant\")\n",
    "        train_data.drop([col], axis=1, inplace=True)\n",
    "    elif train_data[col].nunique() == 2: # Binary columns\n",
    "        continue\n",
    "    elif train_data[col].dtype in ['int64','float64']:\n",
    "        train_data[col] = train_data[col].fillna(train_data[col].median())\n",
    "        num_cols.append(col)\n",
    "    elif train_data[col].nunique() > unique_threshold:\n",
    "        freq_encoded_cols.append(col)\n",
    "    elif 2 < train_data[col].nunique() <= unique_threshold:\n",
    "        ohe_cols.append(col)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_data.columns:\n",
    "    if col in num_cols:\n",
    "        train_data = minmax_encode(train_data, col)\n",
    "    elif col in ohe_cols:\n",
    "        train_data = one_hot_encode(train_data, col)\n",
    "    elif col in freq_encoded_cols:\n",
    "        try:\n",
    "            train_data = frequency_encode(train_data, col)\n",
    "        except:\n",
    "            print(col)\n",
    "    elif train_data[col].nunique() == 1:\n",
    "        train_data.drop(\n",
    "            [col],\n",
    "            axis = 1,\n",
    "            inplace = True\n",
    "        )\n",
    "    else:\n",
    "        train_data[col] = train_data[col].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"PotentialFraud\"]\n",
    "train_data.drop(\n",
    "    [\"PotentialFraud\"],\n",
    "    axis = 1,\n",
    "    inplace = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data in as a Pytorch tensor\n",
    "BATCH_SIZE = 64\n",
    "train_tensor = torch.tensor(train_data.values.tolist())\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset = train_tensor,\n",
    "    shuffle = True,\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_col_count = len(train_data.columns)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()\n",
    "\n",
    "        self.L1 = curr_col_count\n",
    "        self.L2 = curr_col_count//2\n",
    "        self.L3 = curr_col_count//4\n",
    "\n",
    "        self.mean_layer = nn.Linear(self.L3,2)\n",
    "        self.var_layer = nn.Linear(self.L3,2)\n",
    "\n",
    "    def encode(self,x):\n",
    "        model = nn.Sequential(\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L1, self.L2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L2, self.L3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        latent_output = model(x)\n",
    "        mean,var = self.mean_layer(latent_output), self.var_layer(latent_output)\n",
    "        return mean, var\n",
    "    \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)      \n",
    "        z = mean + var*epsilon\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(2, self.L3),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(self.L3, self.L2),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            #nn.Dropout(0.2),\n",
    "            nn.Linear(self.L2, self.L1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        return model(x)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean, var = self.encode(x)\n",
    "        z = self.reparameterization(mean, var)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = VAE().to(device)\n",
    "\n",
    "# Define loss function (sum of binary crossentropy and KL Divergence)\n",
    "def loss_function(x,x_hat,mean,var):\n",
    "    reproduction_loss= nn.functional.binary_cross_entropy(x_hat,x,reduction=\"sum\")\n",
    "    KL_Divergence = -0.5 * torch.sum(1+var-mean.pow(2) - var.exp())\n",
    "    return reproduction_loss+KL_Divergence\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, x in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            x_hat, mean, var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, var)\n",
    "            overall_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*BATCH_SIZE))\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 1 \tAverage Loss:  6.768733373928162e+26\n",
      "\tEpoch 2 \tAverage Loss:  7.760441207732385e+26\n",
      "\tEpoch 3 \tAverage Loss:  6.620213086760895e+28\n",
      "\tEpoch 4 \tAverage Loss:  1.3813026615556926e+30\n",
      "\tEpoch 5 \tAverage Loss:  1.6447547502170093e+26\n",
      "\tEpoch 6 \tAverage Loss:  1.83979407231823e+24\n",
      "\tEpoch 7 \tAverage Loss:  1.657538546747811e+25\n",
      "\tEpoch 8 \tAverage Loss:  7.3283327485117025e+28\n",
      "\tEpoch 9 \tAverage Loss:  1.2050985139676286e+23\n",
      "\tEpoch 10 \tAverage Loss:  2.498136294480587e+26\n",
      "\tEpoch 11 \tAverage Loss:  2.6024523362715715e+24\n",
      "\tEpoch 12 \tAverage Loss:  3.3978787659102344e+29\n",
      "\tEpoch 13 \tAverage Loss:  5.869511168899147e+26\n",
      "\tEpoch 14 \tAverage Loss:  3.8837861458483694e+26\n",
      "\tEpoch 15 \tAverage Loss:  4.7436148409914514e+29\n",
      "\tEpoch 16 \tAverage Loss:  5.9547760031330475e+26\n",
      "\tEpoch 17 \tAverage Loss:  9.023908093299412e+28\n",
      "\tEpoch 18 \tAverage Loss:  1.0676248252823005e+26\n",
      "\tEpoch 19 \tAverage Loss:  4.5152304677738104e+27\n",
      "\tEpoch 20 \tAverage Loss:  1.6034474201484849e+28\n",
      "\tEpoch 21 \tAverage Loss:  1.4970537056564551e+29\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aengu\\OneDrive\\Desktop\\school_stuff\\Y4S1\\DSA4262\\medical-insurance-fraud\\model\\vae.ipynb Cell 18\u001b[0m line \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m EPOCHS \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, optimizer, EPOCHS)\n",
      "\u001b[1;32mc:\\Users\\aengu\\OneDrive\\Desktop\\school_stuff\\Y4S1\\DSA4262\\medical-insurance-fraud\\model\\vae.ipynb Cell 18\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, optimizer, epochs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m x_hat, mean, var \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(x, x_hat, mean, var)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m overall_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[1;32mc:\\Users\\aengu\\OneDrive\\Desktop\\school_stuff\\Y4S1\\DSA4262\\medical-insurance-fraud\\model\\vae.ipynb Cell 18\u001b[0m line \u001b[0;36mloss_function\u001b[1;34m(x, x_hat, mean, var)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_function\u001b[39m(x,x_hat,mean,var):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     reproduction_loss\u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mbinary_cross_entropy(x_hat,x,reduction\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     KL_Divergence \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msum(\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mvar\u001b[39m-\u001b[39mmean\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m var\u001b[39m.\u001b[39mexp())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aengu/OneDrive/Desktop/school_stuff/Y4S1/DSA4262/medical-insurance-fraud/model/vae.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m reproduction_loss\u001b[39m+\u001b[39mKL_Divergence\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\torch\\nn\\functional.py:2893\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2890\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n\u001b[0;32m   2891\u001b[0m     weight \u001b[39m=\u001b[39m weight\u001b[39m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 2893\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight, reduction_enum)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "train(model, optimizer, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
